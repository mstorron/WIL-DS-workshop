{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32225ef8-fe7b-490e-81f2-cfa8530789f9",
   "metadata": {},
   "source": [
    "### Text analysis \n",
    "\n",
    "This notebook conducts text analysis and displays results interactively\n",
    "\n",
    "#### Word analysis:\n",
    "\n",
    "* Frequency analysis of verbs, nouns, and adjectives\n",
    "* Identification of longest words by part of speech\n",
    "* Exploration of words within specific frequency ranges\n",
    "* Calculation of word statistics (total, unique, mean/median frequency)\n",
    "\n",
    "#### Noun Phrase analysis:\n",
    "\n",
    "* Extraction and counting of frequent noun phrases\n",
    "* Identification of least common noun phrases above a minimum frequency\n",
    "* Exploration of noun phrases within a specific frequency range\n",
    "* Detection of longest noun phrases\n",
    "\n",
    "#### Word cloud visualization:\n",
    "\n",
    "* Generation of customizable word clouds for verbs, nouns, and adjectives\n",
    "* Ability to choose color scheme, maximum number of words, and background color\n",
    "\n",
    "#### Usecases:\n",
    "* Terminology extraction\n",
    "* Vocabulary research\n",
    "* Content analysis\n",
    "\n",
    "#### Recommended: familiarity with\n",
    "- Python basics (variables, functions)\n",
    "- Environment management\n",
    "- Directory structure\n",
    "- Package management\n",
    "- Git for version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dff9b-2062-4db4-b71d-d12c48086335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numerical computing library for array operations and mathematical functions\n",
    "from collections import Counter # to count occurrences of items \n",
    "import spacy # library for text processing and linguistic analysis\n",
    "from wordcloud import WordCloud # library for creating word cloud visualizations\n",
    "import matplotlib.pyplot as plt # plotting library for creating static, animated, and interactive visualizations\n",
    "from nltk.corpus import stopwords # Natural Language Toolkit's collection of text corpora, including stopwords\n",
    "import re # regular expressions for pattern matching in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1418ade8-e8a8-4791-8b26-9e297935d039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextPreprocessor:\n",
    "    \"\"\"Handles text loading and preprocessing with lemmatization\"\"\"\n",
    "    def __init__(self, chunk_size=100000):\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "    def load_text(self, file_path):\n",
    "        \"\"\"Load text from file\"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                return file.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file {file_path} was not found.\")\n",
    "            return \"\"\n",
    "            \n",
    "    def split_paragraphs(self, text):\n",
    "        \"\"\"Split text into paragraphs\"\"\"\n",
    "        return [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
    "        \n",
    "    def process_text(self, text):\n",
    "        \"\"\"Process text in chunks to avoid memory issues\"\"\"\n",
    "        paragraphs = self.split_paragraphs(text)\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "        \n",
    "        for para in paragraphs:\n",
    "            if current_length + len(para) > self.chunk_size:\n",
    "                # Process current chunk\n",
    "                chunk_text = '\\n\\n'.join(current_chunk)\n",
    "                chunks.append(self.nlp(chunk_text))\n",
    "                # Start new chunk\n",
    "                current_chunk = [para]\n",
    "                current_length = len(para)\n",
    "            else:\n",
    "                current_chunk.append(para)\n",
    "                current_length += len(para)\n",
    "        \n",
    "        # Process last chunk if it exists\n",
    "        if current_chunk:\n",
    "            chunk_text = '\\n\\n'.join(current_chunk)\n",
    "            chunks.append(self.nlp(chunk_text))\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "class FrequencyAnalyzer:\n",
    "    \"\"\"Handles POS frequency analysis with lemmatization\"\"\"\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_pos_frequencies(self, doc_chunks):\n",
    "        \"\"\"Get frequencies by part of speech from chunks, using lemmas\"\"\"\n",
    "        verbs = Counter()\n",
    "        nouns = Counter()\n",
    "        adjectives = Counter()\n",
    "        \n",
    "        # Process each chunk\n",
    "        if isinstance(doc_chunks, list):\n",
    "            for doc in doc_chunks:\n",
    "                self._process_doc_tokens(doc, verbs, nouns, adjectives)\n",
    "        else:\n",
    "            self._process_doc_tokens(doc_chunks, verbs, nouns, adjectives)\n",
    "        \n",
    "        return (FrequencyDist(verbs), \n",
    "                FrequencyDist(nouns), \n",
    "                FrequencyDist(adjectives))\n",
    "    \n",
    "    def _process_doc_tokens(self, doc, verbs, nouns, adjectives):\n",
    "        \"\"\"Process tokens using lemmas\"\"\"\n",
    "        for token in doc:\n",
    "            if not token.is_stop and token.is_alpha and len(token.text) > 2:\n",
    "                lemma = token.lemma_.lower()\n",
    "                if lemma not in self.preprocessor.stop_words:\n",
    "                    if token.pos_ == \"VERB\":\n",
    "                        verbs[lemma] += 1\n",
    "                    elif token.pos_ == \"NOUN\":\n",
    "                        nouns[lemma] += 1\n",
    "                    elif token.pos_ == \"ADJ\":\n",
    "                        adjectives[lemma] += 1\n",
    "\n",
    "class FrequencyDist:\n",
    "    \"\"\"Custom frequency distribution class\"\"\"\n",
    "    def __init__(self, counter):\n",
    "        self.counter = counter\n",
    "        self._sorted_items = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    def most_common(self, n=None):\n",
    "        \"\"\"Get most frequent words\"\"\"\n",
    "        if n is None:\n",
    "            return self._sorted_items\n",
    "        return self._sorted_items[:n]\n",
    "    \n",
    "    def least_common(self, n=None, min_freq=1):\n",
    "        \"\"\"Get least frequent words above minimum frequency\"\"\"\n",
    "        filtered = [(w, c) for w, c in self._sorted_items if c >= min_freq]\n",
    "        if n is None:\n",
    "            return filtered[::-1]\n",
    "        return filtered[::-1][:n]\n",
    "    \n",
    "    def get_range(self, start=None, end=None):\n",
    "        \"\"\"Get words within frequency range\"\"\"\n",
    "        items = [(w, c) for w, c in self._sorted_items \n",
    "                if (start is None or c >= start) and \n",
    "                   (end is None or c <= end)]\n",
    "        return items\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Calculate statistical measures\"\"\"\n",
    "        frequencies = list(self.counter.values())\n",
    "        return {\n",
    "            'total_occurrences': sum(frequencies),\n",
    "            'unique_words': len(self.counter),\n",
    "            'mean_frequency': np.mean(frequencies),\n",
    "            'median_frequency': np.median(frequencies),\n",
    "            'max_frequency': max(frequencies),\n",
    "            'min_frequency': min(frequencies)\n",
    "        }\n",
    "\n",
    "    def get_longest(self, n=10):\n",
    "        \"\"\"Get n longest words/phrases by character length\"\"\"\n",
    "        sorted_by_length = sorted(self.counter.items(), \n",
    "                            key=lambda x: (len(x[0]), x[1]), \n",
    "                            reverse=True)\n",
    "        return sorted_by_length[:n]\n",
    "    \n",
    "    def items(self):\n",
    "        \"\"\"Return counter items\"\"\"\n",
    "        return self.counter.items()\n",
    "    \n",
    "    def values(self):\n",
    "        \"\"\"Return frequency values\"\"\"\n",
    "        return self.counter.values()\n",
    "    \n",
    "    def keys(self):\n",
    "        \"\"\"Return words\"\"\"\n",
    "        return self.counter.keys()\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"Allow dictionary-style access\"\"\"\n",
    "        return self.counter[key]\n",
    "\n",
    "class PhraseAnalyzer:\n",
    "    \"\"\"Handles noun phrase analysis\"\"\"\n",
    "    def __init__(self, preprocessor):\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_noun_phrases(self, doc_chunks):\n",
    "        \"\"\"Extract and count noun phrases\"\"\"\n",
    "        noun_phrases = Counter()\n",
    "        \n",
    "        for doc in doc_chunks:\n",
    "            for chunk in doc.noun_chunks:\n",
    "                # Clean and normalize the phrase\n",
    "                phrase = ' '.join([token.lemma_.lower() for token in chunk \n",
    "                                 if not token.is_stop and token.is_alpha])\n",
    "                if phrase and len(phrase.split()) > 1:  # Only phrases with 2+ words\n",
    "                    noun_phrases[phrase] += 1\n",
    "        \n",
    "        return FrequencyDist(noun_phrases)\n",
    "\n",
    "class TextAnalyzer:\n",
    "    \"\"\"Main class that coordinates all analysis\"\"\"\n",
    "    def __init__(self, chunk_size=100000):\n",
    "        self.preprocessor = TextPreprocessor(chunk_size=chunk_size)\n",
    "        self.frequency_analyzer = FrequencyAnalyzer(self.preprocessor)\n",
    "        self.phrase_analyzer = PhraseAnalyzer(self.preprocessor)\n",
    "    \n",
    "    def analyze(self, file_path):\n",
    "        \"\"\"Perform complete text analysis\"\"\"\n",
    "        print(\"Loading and preprocessing text...\")\n",
    "        full_text = self.preprocessor.load_text(file_path)\n",
    "        doc_chunks = self.preprocessor.process_text(full_text)\n",
    "        \n",
    "        print(\"Analyzing word frequencies...\")\n",
    "        verbs, nouns, adjectives = self.frequency_analyzer.get_pos_frequencies(doc_chunks)\n",
    "        \n",
    "        print(\"Analyzing noun phrases...\")\n",
    "        noun_phrases = self.phrase_analyzer.get_noun_phrases(doc_chunks)\n",
    "        \n",
    "        return verbs, nouns, adjectives, noun_phrases\n",
    "\n",
    "class WordCloudGenerator:\n",
    "    \"\"\"Handles interactive word cloud generation\"\"\"\n",
    "    def __init__(self):\n",
    "        self.colormap_options = ['viridis', 'Blues', 'Reds', 'Greens', \n",
    "                               'Purples', 'plasma', 'inferno']\n",
    "    \n",
    "    def create_wordcloud(self, freq_dist, title, \n",
    "                        colormap='viridis', \n",
    "                        width=800, \n",
    "                        height=400, \n",
    "                        max_words=100,\n",
    "                        background_color='white'):\n",
    "        \"\"\"Create and display word cloud\"\"\"\n",
    "        wordcloud = WordCloud(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            background_color=background_color,\n",
    "            max_words=max_words,\n",
    "            colormap=colormap\n",
    "        ).generate_from_frequencies(freq_dist.counter)\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    \n",
    "    def interactive_wordcloud(self, freq_dist, pos_name):\n",
    "        \"\"\"Create word cloud with user-specified parameters\"\"\"\n",
    "        print(f\"\\nCreating word cloud for {pos_name}\")\n",
    "        print(\"\\nAvailable color schemes:\")\n",
    "        for i, cmap in enumerate(self.colormap_options, 1):\n",
    "            print(f\"{i}. {cmap}\")\n",
    "        \n",
    "        try:\n",
    "            cmap_choice = int(input(\"\\nChoose color scheme (number): \")) - 1\n",
    "            colormap = self.colormap_options[cmap_choice]\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"Invalid choice, using default (viridis)\")\n",
    "            colormap = 'viridis'\n",
    "        \n",
    "        try:\n",
    "            max_words = int(input(\"Maximum number of words (default 100): \"))\n",
    "        except ValueError:\n",
    "            print(\"Invalid input, using default (100)\")\n",
    "            max_words = 100\n",
    "        \n",
    "        bg_color = input(\"Background color (white/black, default white): \").lower()\n",
    "        if bg_color not in ['white', 'black']:\n",
    "            bg_color = 'white'\n",
    "        \n",
    "        self.create_wordcloud(\n",
    "            freq_dist,\n",
    "            f\"{pos_name} Word Cloud\",\n",
    "            colormap=colormap,\n",
    "            max_words=max_words,\n",
    "            background_color=bg_color\n",
    "        )\n",
    "\n",
    "def interactive_analysis(verbs, nouns, adjectives, noun_phrases):\n",
    "    \"\"\"Interactive function to explore frequencies and create word clouds\"\"\"\n",
    "    wordcloud_gen = WordCloudGenerator()\n",
    "    valid_pos = {'v', 'n', 'a'}\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nAnalysis Options:\")\n",
    "        print(\"1. Word analysis\")\n",
    "        print(\"2. Noun Phrase analysis\")\n",
    "        print(\"3. Create word cloud\")\n",
    "        print(\"4. Show word statistics\")\n",
    "        print(\"5. Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice (1-5): \")\n",
    "        if choice not in ['1', '2', '3', '4', '5']:\n",
    "            print(\"Please enter a valid option (1-5)\")\n",
    "            continue\n",
    "\n",
    "        if choice == '1':\n",
    "            print(\"\\nWord Analysis Options:\")\n",
    "            print(\"1. Most common words\")\n",
    "            print(\"2. Least common words\")\n",
    "            print(\"3. Show words infrequency range\")\n",
    "            print(\"4. Show longest words\")\n",
    "    \n",
    "            word_choice = input(\"\\nEnter your choice (1-4): \")\n",
    "            if word_choice not in ['1', '2', '3', '4']:\n",
    "                print(\"Please enter a valid option (1-4)\")\n",
    "                continue\n",
    "\n",
    "            pos = input(\"Which POS? (v/n/a): \").lower()\n",
    "            if pos not in valid_pos:\n",
    "                print(\"Please enter a valid POS (v for verbs, n for nouns, a for adjectives)\")\n",
    "                continue\n",
    "\n",
    "            freq_dist = {'v': verbs, 'n': nouns, 'a': adjectives}[pos]\n",
    "            pos_name = {'v': 'Verbs', 'n': 'Nouns', 'a': 'Adjectives'}[pos]\n",
    "\n",
    "            if word_choice == '1':\n",
    "                try:\n",
    "                    n = int(input(\"How many words? \"))\n",
    "                    if n <= 0:\n",
    "                        print(\"Please enter a positive number\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number\")\n",
    "                    continue\n",
    "                print(f\"\\nMost common {pos_name.lower()}:\")\n",
    "                for word, count in freq_dist.most_common(n):\n",
    "                    print(f\"{word}: {count}\")\n",
    "                    \n",
    "            elif word_choice == '2':\n",
    "                try:\n",
    "                    n = int(input(\"How many words? \"))\n",
    "                    min_freq = int(input(\"Minimum frequency? \"))\n",
    "                    if n <= 0 or min_freq < 0:\n",
    "                        print(\"Please enter valid numbers (n > 0, min_freq >= 0)\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter valid numbers\")\n",
    "                    continue\n",
    "                print(f\"\\nLeast common {pos_name.lower()} (min freq: {min_freq}):\")\n",
    "                for word, count in freq_dist.least_common(n, min_freq):\n",
    "                    print(f\"{word}: {count}\")\n",
    "                    \n",
    "            elif word_choice == '3':\n",
    "                try:\n",
    "                    start = int(input(\"Start frequency: \"))\n",
    "                    end = int(input(\"End frequency: \"))\n",
    "                    if start < 0 or end < start:\n",
    "                        print(\"Please enter valid frequencies (start >= 0, end >= start)\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter valid numbers\")\n",
    "                    continue\n",
    "                print(f\"\\n{pos_name} with frequency between {start} and {end}:\")\n",
    "                for word, count in freq_dist.get_range(start, end):\n",
    "                    print(f\"{word}: {count}\")\n",
    "\n",
    "            elif word_choice == '4':\n",
    "                try:\n",
    "                    n = int(input(\"How many words? \"))\n",
    "                    if n <= 0:\n",
    "                        print(\"Please enter a positive number\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number\")\n",
    "                    continue\n",
    "                print(f\"\\nLongest {pos_name.lower()}:\")\n",
    "                for word, count in freq_dist.get_longest(n):\n",
    "                    print(f\"{word} ({len(word)} chars): {count} occurrences\")\n",
    "\n",
    "        elif choice == '2':\n",
    "            print(\"\\nNoun Phrase Analysis Options:\")\n",
    "            print(\"1. Most common noun phrases\")\n",
    "            print(\"2. Least common noun phrases\")\n",
    "            print(\"3. Show frequency range\")\n",
    "            print(\"4. Show longest phrases\")\n",
    "    \n",
    "            phrase_choice = input(\"\\nEnter your choice (1-4): \")\n",
    "            if phrase_choice not in ['1', '2', '3', '4']:\n",
    "                print(\"Please enter a valid option (1-4)\")\n",
    "                continue\n",
    "            \n",
    "            if phrase_choice == '1':\n",
    "                try:\n",
    "                    n = int(input(\"How many phrases? \"))\n",
    "                    if n <= 0:\n",
    "                        print(\"Please enter a positive number\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number\")\n",
    "                    continue\n",
    "                print(\"\\nMost common noun phrases:\")\n",
    "                for phrase, count in noun_phrases.most_common(n):\n",
    "                    print(f\"{phrase}: {count}\")\n",
    "                \n",
    "            elif phrase_choice == '2':\n",
    "                try:\n",
    "                    n = int(input(\"How many phrases? \"))\n",
    "                    min_freq = int(input(\"Minimum frequency? \"))\n",
    "                    if n <= 0 or min_freq < 0:\n",
    "                        print(\"Please enter valid numbers (n > 0, min_freq >= 0)\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter valid numbers\")\n",
    "                    continue\n",
    "                print(f\"\\nLeast common noun phrases (min freq: {min_freq}):\")\n",
    "                for phrase, count in noun_phrases.least_common(n, min_freq):\n",
    "                    print(f\"{phrase}: {count}\")\n",
    "                \n",
    "            elif phrase_choice == '3':\n",
    "                try:\n",
    "                    start = int(input(\"Start frequency: \"))\n",
    "                    end = int(input(\"End frequency: \"))\n",
    "                    if start < 0 or end < start:\n",
    "                        print(\"Please enter valid frequencies (start >= 0, end >= start)\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter valid numbers\")\n",
    "                    continue\n",
    "                print(f\"\\nNoun phrases with frequency between {start} and {end}:\")\n",
    "                for phrase, count in noun_phrases.get_range(start, end):\n",
    "                    print(f\"{phrase}: {count}\")\n",
    "\n",
    "            elif phrase_choice == '4':\n",
    "                try:\n",
    "                    n = int(input(\"How many phrases? \"))\n",
    "                    if n <= 0:\n",
    "                        print(\"Please enter a positive number\")\n",
    "                        continue\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number\")\n",
    "                    continue\n",
    "                print(\"\\nLongest noun phrases:\")\n",
    "                for phrase, count in noun_phrases.get_longest(n):\n",
    "                    print(f\"{phrase} ({len(phrase)} chars): {count} occurrences\")\n",
    "                    \n",
    "        elif choice == '3':\n",
    "            pos = input(\"Which POS? (v/n/a): \").lower()\n",
    "            if pos not in valid_pos:\n",
    "                print(\"Please enter a valid POS (v for verbs, n for nouns, a for adjectives)\")\n",
    "                continue\n",
    "            freq_dist = {'v': verbs, 'n': nouns, 'a': adjectives}[pos]\n",
    "            pos_name = {'v': 'Verbs', 'n': 'Nouns', 'a': 'Adjectives'}[pos]\n",
    "            wordcloud_gen.interactive_wordcloud(freq_dist, pos_name)\n",
    "                \n",
    "        elif choice == '4':\n",
    "            for pos_type, freq_dist in [\n",
    "                (\"Verbs\", verbs),\n",
    "                (\"Nouns\", nouns),\n",
    "                (\"Adjectives\", adjectives)\n",
    "            ]:\n",
    "                stats = freq_dist.get_stats()\n",
    "                print(f\"\\n{pos_type} Statistics:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"Total {pos_type.lower()}: {stats['total_occurrences']}\")\n",
    "                print(f\"Unique {pos_type.lower()}: {stats['unique_words']}\")\n",
    "                print(f\"Average frequency: {stats['mean_frequency']:.2f}\")\n",
    "                print(f\"Median frequency: {stats['median_frequency']:.2f}\")\n",
    "                print(f\"Most frequent: {stats['max_frequency']}\")\n",
    "                print(f\"Least frequent: {stats['min_frequency']}\")\n",
    "                            \n",
    "        elif choice == '5':\n",
    "            break\n",
    "            \n",
    "        input(\"\\nPress Enter to continue...\")\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = TextAnalyzer(chunk_size=100000)\n",
    "    verbs, nouns, adjectives, noun_phrases = analyzer.analyze('input_data/ulysses.txt')\n",
    "    interactive_analysis(verbs, nouns, adjectives, noun_phrases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
